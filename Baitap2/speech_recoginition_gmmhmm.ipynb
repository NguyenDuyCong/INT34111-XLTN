{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    yt, index = librosa.effects.trim(y) # Trim the beginning and ending silence\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        yt, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # energy feature\n",
    "    rms = librosa.feature.rms(y, hop_length=hop_length)\n",
    "    frame_feature = np.concatenate([mfcc, rms], axis=0)\n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(frame_feature, order=1, mode='nearest')\n",
    "    delta2 = librosa.feature.delta(frame_feature, order=2, mode='nearest')\n",
    "    # X is 39 x T\n",
    "    X = np.concatenate([frame_feature, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 39 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc = get_mfcc(\"./data/duong/17.wav\")\n",
    "# mfcc\n",
    "y, sr = librosa.load(\"./data/duong/17.wav\") # read .wav file\n",
    "yt, index = librosa.effects.trim(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.07823925, -0.1147735 , -0.10022258, ...,  0.07561673,\n",
       "         0.07219956,  0.07881433], dtype=float32),\n",
       " array([-0.07823925, -0.1147735 , -0.10022258, ...,  0.07561673,\n",
       "         0.07219956,  0.07881433], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load hai dataset\n",
      "Load tien dataset\n",
      "Load duong dataset\n",
      "Load y_te dataset\n",
      "Load benh_nhan dataset\n",
      "Load test_hai dataset\n",
      "Load test_tien dataset\n",
      "Load test_duong dataset\n",
      "Load test_y_te dataset\n",
      "Load test_benh_nhan dataset\n",
      "vectors (24281, 39)\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"hai\", \"tien\", \"duong\", \"y_te\", \"benh_nhan\", \"test_hai\", \"test_tien\", \"test_duong\", \"test_y_te\", \"test_benh_nhan\"]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "# kmeans = clustering(all_vectors)\n",
    "# print(\"centers\", kmeans.cluster_centers_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initByBakis(nStates, bakisLevel):\n",
    "        ''' init start_prob and transmat_prob by Bakis model ''' \n",
    "        startprobPrior = np.zeros(nStates)\n",
    "        startprobPrior[0 : bakisLevel - 1] = 1./ (bakisLevel - 1)\n",
    "         \n",
    "        transmatPrior = getTransmatPrior(nStates, bakisLevel)\n",
    "         \n",
    "        return startprobPrior, transmatPrior\n",
    "    \n",
    "def getTransmatPrior(nStates, bakisLevel):\n",
    "    ''' get transmat prior '''\n",
    "    transmatPrior = (1. / bakisLevel) * np.eye(nStates)\n",
    "\n",
    "    for i in range(nStates - (bakisLevel - 1)):\n",
    "        for j in range(bakisLevel - 1):\n",
    "            transmatPrior[i, i + j + 1] = 1. /  bakisLevel\n",
    "\n",
    "    for i in range(nStates - bakisLevel + 1, nStates):\n",
    "        for j in range(nStates - i -j):\n",
    "            transmatPrior[i, i + j] = 1. / (nStates - i)\n",
    "\n",
    "    return transmatPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class hai\n",
      "(2107, 39) [19, 26, 15, 26, 23, 20, 16, 24, 33, 21, 15, 19, 20, 19, 23, 18, 15, 25, 23, 20, 19, 24, 16, 16, 22, 27, 27, 14, 14, 18, 20, 34, 13, 13, 13, 21, 14, 19, 16, 18, 30, 15, 11, 16, 27, 17, 16, 28, 14, 26, 14, 33, 40, 24, 22, 14, 28, 17, 12, 21, 18, 32, 26, 17, 21, 17, 13, 17, 18, 13, 8, 16, 12, 15, 14, 10, 28, 18, 12, 127, 106, 114, 93, 119] 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -183056.6780             +nan\n",
      "         2     -161186.2651      +21870.4129\n",
      "         3     -156622.7877       +4563.4773\n",
      "         4     -154629.5130       +1993.2747\n",
      "         5     -153525.3545       +1104.1585\n",
      "         6     -152966.5886        +558.7659\n",
      "         7     -152572.5550        +394.0336\n",
      "         8     -152239.4211        +333.1339\n",
      "         9     -152088.1209        +151.3002\n",
      "        10     -152004.0695         +84.0514\n",
      "        11     -151926.7850         +77.2845\n",
      "        12     -151847.7277         +79.0573\n",
      "        13     -151735.4266        +112.3011\n",
      "        14     -151610.9184        +124.5082\n",
      "        15     -151540.9472         +69.9712\n",
      "        16     -151467.3027         +73.6444\n",
      "        17     -151381.8408         +85.4620\n",
      "        18     -151341.2566         +40.5842\n",
      "        19     -151322.9671         +18.2895\n",
      "        20     -151280.7228         +42.2443\n",
      "        21     -151243.7288         +36.9940\n",
      "        22     -151235.5708          +8.1580\n",
      "        23     -151232.4843          +3.0865\n",
      "        24     -151222.0662         +10.4181\n",
      "        25     -151210.5739         +11.4924\n",
      "        26     -151194.6135         +15.9604\n",
      "        27     -151182.2283         +12.3852\n",
      "        28     -151177.0264          +5.2020\n",
      "        29     -151176.3343          +0.6920\n",
      "        30     -151175.8293          +0.5050\n",
      "        31     -151175.4394          +0.3899\n",
      "        32     -151175.0255          +0.4139\n",
      "        33     -151174.4771          +0.5485\n",
      "        34     -151173.8306          +0.6465\n",
      "        35     -151173.0561          +0.7745\n",
      "        36     -151172.2589          +0.7972\n",
      "        37     -151171.7216          +0.5373\n",
      "        38     -151171.2858          +0.4358\n",
      "        39     -151170.9270          +0.3588\n",
      "        40     -151170.5895          +0.3374\n",
      "        41     -151170.0148          +0.5748\n",
      "        42     -151168.8881          +1.1267\n",
      "        43     -151167.9660          +0.9221\n",
      "        44     -151166.7700          +1.1960\n",
      "        45     -151165.3942          +1.3758\n",
      "        46     -151164.4757          +0.9184\n",
      "        47     -151163.4840          +0.9917\n",
      "        48     -151161.7081          +1.7759\n",
      "        49     -151155.6093          +6.0987\n",
      "        50     -151150.8298          +4.7795\n",
      "        51     -151150.7303          +0.0996\n",
      "        52     -151150.6748          +0.0554\n",
      "        53     -151150.5730          +0.1018\n",
      "        54     -151150.2920          +0.2809\n",
      "        55     -151149.7724          +0.5197\n",
      "        56     -151149.5329          +0.2395\n",
      "        57     -151149.4811          +0.0518\n",
      "        58     -151149.4605          +0.0206\n",
      "        59     -151149.4518          +0.0086\n"
     ]
    }
   ],
   "source": [
    "cname = \"hai\"\n",
    "n_coms = 9\n",
    "startprobPrior,transmatPrior = initByBakis(nStates=n_coms,bakisLevel=3)\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "    n_components = n_coms, n_mix = 2, n_iter = 1000,verbose= True,\n",
    "    params='mctw',\n",
    "    init_params='mcw',\n",
    "    startprob_prior = startprobPrior,\n",
    "    transmat_prior = transmatPrior\n",
    ")\n",
    "\n",
    "X = np.concatenate(dataset[cname])\n",
    "lengths = list([len(x) for x in dataset[cname]])\n",
    "print(\"training class\", cname)\n",
    "print(X.shape, lengths, len(lengths))\n",
    "hmm.fit(X)\n",
    "models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class tien\n",
      "(3602, 39) [13, 14, 18, 19, 16, 18, 24, 21, 16, 20, 17, 24, 18, 26, 19, 16, 16, 29, 24, 28, 19, 36, 25, 26, 29, 24, 23, 31, 29, 25, 14, 24, 18, 18, 19, 18, 16, 19, 24, 16, 19, 13, 21, 55, 17, 28, 25, 20, 41, 23, 24, 20, 14, 13, 24, 29, 41, 26, 26, 36, 25, 18, 25, 18, 28, 18, 19, 19, 24, 55, 29, 26, 24, 21, 16, 31, 24, 19, 17, 16, 28, 25, 23, 16, 104, 104, 99, 109, 109, 112, 112, 114, 124, 106, 117, 112, 124, 114, 114] 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -311725.8752             +nan\n",
      "         2     -260966.8961      +50758.9791\n",
      "         3     -253172.6310       +7794.2651\n",
      "         4     -250574.1550       +2598.4760\n",
      "         5     -249130.9083       +1443.2467\n",
      "         6     -248506.1776        +624.7306\n",
      "         7     -248279.3399        +226.8377\n",
      "         8     -248102.1351        +177.2048\n",
      "         9     -247891.9669        +210.1682\n",
      "        10     -247676.7523        +215.2146\n",
      "        11     -247549.0576        +127.6947\n",
      "        12     -247509.5944         +39.4632\n",
      "        13     -247462.5272         +47.0672\n",
      "        14     -247414.0364         +48.4908\n",
      "        15     -247347.3075         +66.7289\n",
      "        16     -247298.2668         +49.0407\n",
      "        17     -247272.9826         +25.2842\n",
      "        18     -247232.0615         +40.9211\n",
      "        19     -247200.7552         +31.3062\n",
      "        20     -247007.1272        +193.6281\n",
      "        21     -246939.4264         +67.7008\n",
      "        22     -246904.2709         +35.1555\n",
      "        23     -246872.7541         +31.5168\n",
      "        24     -246853.8365         +18.9175\n",
      "        25     -246846.4988          +7.3378\n",
      "        26     -246837.5502          +8.9486\n",
      "        27     -246826.8712         +10.6789\n",
      "        28     -246823.5906          +3.2806\n",
      "        29     -246820.7486          +2.8420\n",
      "        30     -246818.1847          +2.5639\n",
      "        31     -246816.6014          +1.5833\n",
      "        32     -246815.7695          +0.8319\n",
      "        33     -246816.9066          -1.1371\n"
     ]
    }
   ],
   "source": [
    "cname = \"tien\"\n",
    "n_coms = 9\n",
    "startprobPrior,transmatPrior = initByBakis(nStates=n_coms,bakisLevel=3)\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "    n_components = n_coms, n_mix = 2, n_iter = 1000,verbose= True,\n",
    "    params='mctw',\n",
    "    init_params='mcw',\n",
    "    startprob_prior = startprobPrior,\n",
    "    transmat_prior = transmatPrior\n",
    ")\n",
    "\n",
    "X = np.concatenate(dataset[cname])\n",
    "lengths = list([len(x) for x in dataset[cname]])\n",
    "print(\"training class\", cname)\n",
    "print(X.shape, lengths, len(lengths))\n",
    "hmm.fit(X)\n",
    "models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class benh_nhan\n",
      "(6393, 39) [51, 39, 41, 47, 41, 65, 39, 52, 43, 48, 59, 68, 38, 50, 32, 40, 66, 50, 44, 41, 102, 44, 38, 49, 56, 44, 48, 33, 35, 54, 37, 38, 58, 32, 42, 61, 51, 47, 49, 40, 52, 31, 62, 56, 47, 35, 36, 58, 49, 39, 35, 40, 36, 42, 32, 34, 49, 53, 42, 40, 39, 45, 39, 40, 54, 50, 40, 58, 37, 46, 41, 33, 27, 27, 50, 45, 50, 52, 35, 45, 56, 37, 42, 65, 55, 42, 50, 37, 37, 45, 47, 269, 189, 155, 163, 145, 143, 114, 145, 130, 130, 140, 119, 153, 130, 122] 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -587381.4144             +nan\n",
      "         2     -506948.0049      +80433.4094\n",
      "         3     -491520.9637      +15427.0413\n",
      "         4     -486264.8993       +5256.0644\n",
      "         5     -483233.8368       +3031.0625\n",
      "         6     -482153.8136       +1080.0232\n",
      "         7     -481452.1055        +701.7081\n",
      "         8     -480985.6358        +466.4697\n",
      "         9     -480673.9112        +311.7246\n",
      "        10     -480469.0823        +204.8289\n",
      "        11     -480243.6767        +225.4056\n",
      "        12     -480044.7718        +198.9050\n",
      "        13     -479894.8932        +149.8785\n",
      "        14     -479844.6647         +50.2285\n",
      "        15     -479783.3213         +61.3434\n",
      "        16     -479700.0287         +83.2926\n",
      "        17     -479636.7914         +63.2373\n",
      "        18     -479564.1140         +72.6774\n",
      "        19     -479507.2783         +56.8357\n",
      "        20     -479438.1449         +69.1334\n",
      "        21     -479351.1383         +87.0067\n",
      "        22     -479268.6049         +82.5334\n",
      "        23     -479174.4620         +94.1429\n",
      "        24     -479051.8954        +122.5666\n",
      "        25     -478885.7140        +166.1813\n",
      "        26     -478761.8592        +123.8549\n",
      "        27     -478669.1534         +92.7058\n",
      "        28     -478590.5509         +78.6025\n",
      "        29     -478519.7438         +70.8071\n",
      "        30     -478489.8532         +29.8906\n",
      "        31     -478466.7085         +23.1447\n",
      "        32     -478454.5315         +12.1771\n",
      "        33     -478446.2544          +8.2771\n",
      "        34     -478438.4434          +7.8110\n",
      "        35     -478426.2062         +12.2372\n",
      "        36     -478418.2277          +7.9785\n",
      "        37     -478413.6918          +4.5359\n",
      "        38     -478410.0234          +3.6685\n",
      "        39     -478403.9721          +6.0513\n",
      "        40     -478399.8081          +4.1640\n",
      "        41     -478396.6204          +3.1878\n",
      "        42     -478393.0677          +3.5527\n",
      "        43     -478390.4462          +2.6214\n",
      "        44     -478388.7702          +1.6761\n",
      "        45     -478387.6047          +1.1655\n",
      "        46     -478386.7450          +0.8597\n",
      "        47     -478386.0573          +0.6877\n",
      "        48     -478385.4365          +0.6207\n",
      "        49     -478384.7897          +0.6469\n",
      "        50     -478384.0609          +0.7287\n",
      "        51     -478383.0270          +1.0339\n",
      "        52     -478380.0559          +2.9712\n",
      "        53     -478375.5680          +4.4879\n",
      "        54     -478373.0198          +2.5482\n",
      "        55     -478362.0016         +11.0182\n",
      "        56     -478350.3398         +11.6617\n",
      "        57     -478331.9932         +18.3466\n",
      "        58     -478323.7922          +8.2010\n",
      "        59     -478293.4606         +30.3316\n",
      "        60     -478248.5856         +44.8750\n",
      "        61     -478224.2546         +24.3310\n",
      "        62     -478203.4139         +20.8407\n",
      "        63     -478191.2434         +12.1705\n",
      "        64     -478180.4897         +10.7537\n",
      "        65     -478164.9624         +15.5272\n",
      "        66     -478147.4336         +17.5288\n",
      "        67     -478109.8363         +37.5973\n",
      "        68     -478096.9149         +12.9214\n",
      "        69     -478093.7915          +3.1233\n",
      "        70     -478083.7966          +9.9949\n",
      "        71     -478082.1238          +1.6728\n",
      "        72     -478055.5056         +26.6182\n",
      "        73     -478047.7288          +7.7769\n",
      "        74     -478037.3408         +10.3880\n",
      "        75     -478031.3256          +6.0151\n",
      "        76     -478028.7657          +2.5600\n",
      "        77     -478027.7617          +1.0040\n",
      "        78     -478025.4606          +2.3011\n",
      "        79     -478016.1714          +9.2891\n",
      "        80     -478015.1009          +1.0705\n",
      "        81     -478014.0556          +1.0453\n",
      "        82     -478013.0924          +0.9632\n",
      "        83     -478012.4779          +0.6145\n",
      "        84     -478010.7390          +1.7389\n",
      "        85     -478009.2329          +1.5060\n",
      "        86     -478009.0624          +0.1705\n",
      "        87     -478008.9939          +0.0684\n",
      "        88     -478008.9359          +0.0580\n",
      "        89     -478008.8758          +0.0602\n",
      "        90     -478008.8031          +0.0727\n",
      "        91     -478008.6927          +0.1104\n",
      "        92     -478008.4642          +0.2285\n",
      "        93     -478007.9014          +0.5628\n",
      "        94     -478007.0073          +0.8941\n",
      "        95     -478006.4701          +0.5372\n",
      "        96     -478006.2203          +0.2498\n",
      "        97     -478006.0527          +0.1676\n",
      "        98     -478005.9095          +0.1432\n",
      "        99     -478005.7619          +0.1476\n",
      "       100     -478005.5726          +0.1893\n",
      "       101     -478005.2535          +0.3191\n",
      "       102     -478004.5287          +0.7249\n",
      "       103     -478002.3411          +2.1876\n",
      "       104     -477998.4564          +3.8846\n",
      "       105     -477994.2229          +4.2336\n",
      "       106     -477986.6134          +7.6095\n",
      "       107     -477975.9479         +10.6655\n",
      "       108     -477953.9649         +21.9830\n",
      "       109     -477939.2473         +14.7176\n",
      "       110     -477933.0687          +6.1787\n",
      "       111     -477934.1030          -1.0343\n"
     ]
    }
   ],
   "source": [
    "cname = \"benh_nhan\"\n",
    "n_coms = 18\n",
    "startprobPrior,transmatPrior = initByBakis(nStates=n_coms,bakisLevel=3)\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "    n_components = n_coms, n_mix = 2, n_iter = 1000,verbose= True,\n",
    "    params='mctw',\n",
    "    init_params='mcw',\n",
    "    startprob_prior = startprobPrior,\n",
    "    transmat_prior = transmatPrior\n",
    ")\n",
    "\n",
    "X = np.concatenate(dataset[cname])\n",
    "lengths = list([len(x) for x in dataset[cname]])\n",
    "print(\"training class\", cname)\n",
    "print(X.shape, lengths, len(lengths))\n",
    "hmm.fit(X)\n",
    "models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class y_te\n",
      "(6673, 39) [32, 44, 37, 50, 39, 44, 50, 39, 43, 63, 40, 62, 41, 47, 42, 37, 32, 44, 37, 50, 42, 49, 31, 46, 45, 34, 64, 58, 49, 72, 60, 59, 58, 39, 37, 49, 49, 39, 44, 50, 39, 60, 56, 52, 44, 61, 54, 39, 40, 76, 63, 37, 35, 51, 42, 41, 49, 41, 58, 59, 57, 38, 44, 53, 46, 54, 50, 46, 38, 50, 45, 47, 55, 57, 43, 38, 44, 35, 41, 58, 53, 38, 51, 61, 57, 48, 47, 63, 49, 34, 59, 43, 259, 173, 143, 155, 143, 135, 148, 143, 140, 140, 145, 135, 148, 132, 148] 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -602977.5957             +nan\n",
      "         2     -523332.3958      +79645.1999\n",
      "         3     -506495.8708      +16836.5251\n",
      "         4     -500956.8689       +5539.0018\n",
      "         5     -498651.5065       +2305.3625\n",
      "         6     -497760.6293        +890.8772\n",
      "         7     -497149.1951        +611.4342\n",
      "         8     -496751.3624        +397.8327\n",
      "         9     -496621.1710        +130.1914\n",
      "        10     -496568.8399         +52.3311\n",
      "        11     -496525.7246         +43.1153\n",
      "        12     -496486.6590         +39.0656\n",
      "        13     -496422.9062         +63.7527\n",
      "        14     -496378.8815         +44.0247\n",
      "        15     -496368.1524         +10.7292\n",
      "        16     -496361.1176          +7.0348\n",
      "        17     -496355.2209          +5.8967\n",
      "        18     -496348.7621          +6.4588\n",
      "        19     -496340.2681          +8.4940\n",
      "        20     -496332.3429          +7.9252\n",
      "        21     -496326.1879          +6.1550\n",
      "        22     -496308.9991         +17.1887\n",
      "        23     -496293.4741         +15.5251\n",
      "        24     -496290.2490          +3.2251\n",
      "        25     -496287.1122          +3.1367\n",
      "        26     -496284.2850          +2.8273\n",
      "        27     -496282.3623          +1.9226\n",
      "        28     -496280.8963          +1.4660\n",
      "        29     -496279.6316          +1.2646\n",
      "        30     -496278.3762          +1.2554\n",
      "        31     -496276.8962          +1.4801\n",
      "        32     -496274.9499          +1.9463\n",
      "        33     -496272.2996          +2.6503\n",
      "        34     -496267.4872          +4.8124\n",
      "        35     -496256.3733         +11.1139\n",
      "        36     -496234.8318         +21.5415\n",
      "        37     -496224.0569         +10.7749\n",
      "        38     -496219.9319          +4.1250\n",
      "        39     -496217.2396          +2.6923\n",
      "        40     -496215.3783          +1.8612\n",
      "        41     -496213.7096          +1.6687\n",
      "        42     -496212.2844          +1.4252\n",
      "        43     -496211.0743          +1.2102\n",
      "        44     -496209.9424          +1.1319\n",
      "        45     -496208.7430          +1.1994\n",
      "        46     -496207.4439          +1.2991\n",
      "        47     -496206.1985          +1.2454\n",
      "        48     -496205.1027          +1.0958\n",
      "        49     -496204.2584          +0.8443\n",
      "        50     -496203.7537          +0.5047\n",
      "        51     -496203.4643          +0.2894\n",
      "        52     -496203.2548          +0.2095\n",
      "        53     -496203.0621          +0.1927\n",
      "        54     -496202.8647          +0.1975\n",
      "        55     -496202.6638          +0.2009\n",
      "        56     -496202.4708          +0.1929\n",
      "        57     -496202.2920          +0.1788\n",
      "        58     -496202.1247          +0.1673\n",
      "        59     -496201.9632          +0.1615\n",
      "        60     -496201.8014          +0.1617\n",
      "        61     -496201.6331          +0.1684\n",
      "        62     -496201.4502          +0.1828\n",
      "        63     -496201.2430          +0.2072\n",
      "        64     -496200.9993          +0.2438\n",
      "        65     -496200.7065          +0.2928\n",
      "        66     -496200.3606          +0.3460\n",
      "        67     -496199.9794          +0.3812\n",
      "        68     -496199.6064          +0.3730\n",
      "        69     -496199.2934          +0.3130\n",
      "        70     -496199.0753          +0.2181\n",
      "        71     -496198.9399          +0.1353\n",
      "        72     -496198.8535          +0.0865\n",
      "        73     -496198.7951          +0.0584\n",
      "        74     -496198.7547          +0.0404\n",
      "        75     -496198.7264          +0.0283\n",
      "        76     -496198.7063          +0.0201\n",
      "        77     -496198.6919          +0.0144\n",
      "        78     -496198.6814          +0.0105\n",
      "        79     -496198.6736          +0.0078\n"
     ]
    }
   ],
   "source": [
    "cname = \"y_te\"\n",
    "n_coms = 9\n",
    "startprobPrior,transmatPrior = initByBakis(nStates=n_coms,bakisLevel=3)\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "    n_components = n_coms, n_mix = 2, n_iter = 1000,verbose= True,\n",
    "    params='mctw',\n",
    "    init_params='mcw',\n",
    "    startprob_prior = startprobPrior,\n",
    "    transmat_prior = transmatPrior\n",
    ")\n",
    "\n",
    "X = np.concatenate(dataset[cname])\n",
    "lengths = list([len(x) for x in dataset[cname]])\n",
    "print(\"training class\", cname)\n",
    "print(X.shape, lengths, len(lengths))\n",
    "hmm.fit(X)\n",
    "models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class duong\n",
      "(3201, 39) [19, 47, 23, 17, 19, 16, 36, 19, 19, 19, 21, 14, 17, 15, 35, 22, 36, 22, 16, 15, 24, 18, 16, 19, 26, 36, 38, 38, 35, 27, 24, 19, 47, 14, 32, 18, 15, 24, 27, 33, 17, 23, 19, 18, 17, 28, 20, 19, 16, 32, 21, 285, 114, 158, 124, 150, 106, 119, 132, 106, 114, 124, 109, 122, 101, 130] 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -268982.8755             +nan\n",
      "         2     -224789.3043      +44193.5712\n",
      "         3     -216829.9337       +7959.3706\n",
      "         4     -214199.9177       +2630.0160\n",
      "         5     -213076.5529       +1123.3647\n",
      "         6     -212467.3173        +609.2356\n",
      "         7     -212178.9717        +288.3457\n",
      "         8     -212036.5073        +142.4644\n",
      "         9     -211950.8811         +85.6262\n",
      "        10     -211887.9116         +62.9695\n",
      "        11     -211833.3467         +54.5649\n",
      "        12     -211783.3689         +49.9778\n",
      "        13     -211698.0226         +85.3463\n",
      "        14     -211631.1529         +66.8696\n",
      "        15     -211577.0204         +54.1325\n",
      "        16     -211497.6261         +79.3944\n",
      "        17     -211469.8053         +27.8207\n",
      "        18     -211446.4288         +23.3766\n",
      "        19     -211409.8102         +36.6186\n",
      "        20     -211375.9082         +33.9020\n",
      "        21     -211327.4997         +48.4085\n",
      "        22     -211316.1670         +11.3327\n",
      "        23     -211307.9278          +8.2393\n",
      "        24     -211301.3318          +6.5960\n",
      "        25     -211297.9762          +3.3556\n",
      "        26     -211296.8767          +1.0995\n",
      "        27     -211295.8419          +1.0348\n",
      "        28     -211293.7364          +2.1055\n",
      "        29     -211291.4109          +2.3255\n",
      "        30     -211289.5626          +1.8483\n",
      "        31     -211283.0434          +6.5192\n",
      "        32     -211268.7032         +14.3402\n",
      "        33     -211247.6507         +21.0525\n",
      "        34     -211243.8019          +3.8488\n",
      "        35     -211238.4568          +5.3451\n",
      "        36     -211220.8730         +17.5838\n",
      "        37     -211209.6547         +11.2183\n",
      "        38     -211206.6876          +2.9671\n",
      "        39     -211206.1246          +0.5631\n",
      "        40     -211205.8026          +0.3219\n",
      "        41     -211205.5084          +0.2942\n",
      "        42     -211205.2019          +0.3065\n",
      "        43     -211204.9505          +0.2514\n",
      "        44     -211204.8260          +0.1245\n",
      "        45     -211204.7864          +0.0396\n",
      "        46     -211204.7774          +0.0090\n"
     ]
    }
   ],
   "source": [
    "cname = \"duong\"\n",
    "n_coms = 9\n",
    "startprobPrior,transmatPrior = initByBakis(nStates=n_coms,bakisLevel=3)\n",
    "hmm = hmmlearn.hmm.GMMHMM(\n",
    "    n_components = n_coms, n_mix = 2, n_iter = 1000,verbose= True,\n",
    "    params='mctw',\n",
    "    init_params='mcw',\n",
    "    startprob_prior = startprobPrior,\n",
    "    transmat_prior = transmatPrior\n",
    ")\n",
    "\n",
    "X = np.concatenate(dataset[cname])\n",
    "lengths = list([len(x) for x in dataset[cname]])\n",
    "print(\"training class\", cname)\n",
    "print(X.shape, lengths, len(lengths))\n",
    "hmm.fit(X)\n",
    "models[cname] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hai': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -...\n",
       "        [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "         0.33333333, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "         0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        ]]),\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'tien': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -...\n",
       "        [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "         0.33333333, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "         0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        ]]),\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'benh_nhan': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.5, -1.5, -1.5, ..., -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, ....\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ]]),\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'y_te': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -...\n",
       "        [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "         0.33333333, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "         0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        ]]),\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])),\n",
       " 'duong': GMMHMM(algorithm='viterbi', covariance_type='diag',\n",
       "        covars_prior=array([[[-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5],\n",
       "         [-1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5,\n",
       "          -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -...\n",
       "        [0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "         0.33333333, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "         0.33333333, 0.33333333, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.33333333, 0.33333333, 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        ]]),\n",
       "        verbose=True,\n",
       "        weights_prior=array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]))}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_tien tien\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_duong duong\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_y_te y_te\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_hai hai\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "test_benh_nhan benh_nhan\n",
      "{'test_tien': 1.0, 'test_duong': 1.0, 'test_y_te': 1.0, 'test_hai': 1.0, 'test_benh_nhan': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "accuracy = {}\n",
    "test_name = {\"test_y_te\", \"test_hai\", \"test_benh_nhan\", \"test_duong\", \"test_tien\"}\n",
    "for true_cname in test_name:\n",
    "    k = 0\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        inverse = [(value, key) for key, value in score.items()]\n",
    "        predict = max(inverse)[1]\n",
    "        print(true_cname, predict)\n",
    "        if predict == true_cname[5:]:\n",
    "            k +=1\n",
    "    accuracy[true_cname] = k/len(dataset[true_cname])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"gmm_hmm2.pkl\", \"wb\") as file:\n",
    "    pickle.dump(models, file)\n",
    "print(\"Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit0d02a1b1d65743c3aa043d986ab8b5ed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
